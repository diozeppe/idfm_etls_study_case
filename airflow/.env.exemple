# IDFM
IDFM_API_KEY = ""

# AIRFLOW

AIRFLOW_VERSION = "3.0.6"

# Postgres
POSTGRES_USER = "airflow"
POSTGRES_PASSWORD = "airflow"
POSTGRES_DB = "airflow"
POSTGRES_IDFM_DB = "idfm_db"

# Core

#
# Use "id -u" to get your id value
#
AIRFLOW_UID = ""
AIRFLOW__CORE__EXECUTOR = "LocalExecutor"

#
# Use the following code to generate a key:
# python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
#
AIRFLOW__CORE__FERNET_KEY = ""

AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION = "true"
AIRFLOW__CORE__EXECUTION_API_SERVER_URL = "http://airflow-apiserver-1:8080/execution/"
AIRFLOW__CORE__AUTH_MANAGER = "airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager"

# Scheduler
AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK = "true"
SETUP_SQL_FILE_PATH = "/opt/airflow/dags/ddl/schema/setup.sql"

# API server
_AIRFLOW_WWW_USER_CREATE = "true"
_AIRFLOW_WWW_USER_USERNAME = "airflow"
_AIRFLOW_WWW_USER_PASSWORD = "airflow"
_AIRFLOW_DB_MIGRATE = "true"
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN = "postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB}"

#
# Use the following code to generate a key:
# python3 -c 'import secrets; print(secrets.token_hex(32))'
#
AIRFLOW__API_AUTH__JWT_SECRET = ""

#
# DAG Processor
# Important for DAGs created dynamically 
#
AIRFLOW__CORE__DAGBAG_IMPORT_TIMEOUT = 60
AIRFLOW__DAG_PROCESSOR__DAG_FILE_PROCESSOR_TIMEOUT = 100